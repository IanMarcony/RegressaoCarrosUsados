# -*- coding: utf-8 -*-
"""RegressaoCarrosUsadosCrossValidation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zhmz1K3GfKPa4SGHRvlm4yzOY6DHdDKI

#Regressao usando base de Carros usados com Validação Cruzada
"""

#Importar dados essenciais
import pandas as pd
import numpy as np
from keras.models import Sequential
from keras.layers import Dense
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import cross_val_score

!pip install scikeras

from scikeras.wrappers import KerasRegressor


from google.colab import drive
drive.mount('/content/drive/')

dataset = pd.read_csv('/content/drive/My Drive/CursoIA/RegressaoCarrosUsados/autos.csv', encoding='ISO-8859-1')

#Removendo colunas de dataset que não tem relação com o preço do Veículo

dataset = dataset.drop('dateCrawled', axis=1)
dataset = dataset.drop('dateCreated', axis=1)
dataset = dataset.drop('postalCode', axis=1)
dataset = dataset.drop('nrOfPictures', axis=1)
dataset = dataset.drop('lastSeen', axis=1)
dataset = dataset.drop('name', axis=1)
dataset = dataset.drop('seller', axis=1)
dataset = dataset.drop('offerType', axis=1)
inconsistent = dataset.loc[dataset.price <=10]
dataset = dataset.loc[dataset.price>10]
inconsistent = dataset.loc[dataset.price>350000]
dataset = dataset.loc[dataset.price<350000]

#Removendo registros NAN
print(dataset['vehicleType'].value_counts()) #limousine
print(dataset['gearbox'].value_counts()) #manuell
print(dataset['model'].value_counts()) #golf
print(dataset['fuelType'].value_counts()) #benzin
print(dataset['notRepairedDamage'].value_counts()) #nein

values = {'vehicleType':'limousine',
          'gearbox':'manuell',
          'model':'golf',
          'fuelType':'benzin',
          'notRepairedDamage':'nein'}
dataset = dataset.fillna(value = values)

previsores = dataset.iloc[:, 1:13].values
preco_real = dataset.iloc[:, 0].values

labelEncoder_previsores =  LabelEncoder()

previsores[:,0] = labelEncoder_previsores.fit_transform(previsores[:,0])
previsores[:,1] = labelEncoder_previsores.fit_transform(previsores[:,1])
previsores[:,3] = labelEncoder_previsores.fit_transform(previsores[:,3])
previsores[:,5] = labelEncoder_previsores.fit_transform(previsores[:,5])
previsores[:,8] = labelEncoder_previsores.fit_transform(previsores[:,8])
previsores[:,9] = labelEncoder_previsores.fit_transform(previsores[:,9])
previsores[:,10] = labelEncoder_previsores.fit_transform(previsores[:,10])


columnTransformer = ColumnTransformer([('encoder', OneHotEncoder(), [0,1,3,5,8,9,10])],     remainder='passthrough')
previsores=columnTransformer.fit_transform(previsores).toarray()

# Hora de criar a rede neural

def criar_rede():
  regressor = Sequential()

  regressor.add(Dense(units = 158, activation = 'relu', input_dim = 316))
  regressor.add(Dense(units = 158, activation = 'relu'))
  regressor.add(Dense(units = 1, activation = 'linear'))
  regressor.compile(loss = 'mean_absolute_error',
                    optimizer = 'adam',
                    metrics = ['mean_absolute_error'])
  return regressor

"""#Realizando validação cruzada"""

regressor = KerasRegressor(build_fn = criar_rede,
                           epochs = 100,
                           batch_size = 300)

resultados = cross_val_score(estimator = regressor,
                             X = previsores, y = preco_real,
                             cv = 10, scoring = 'neg_mean_absolute_error')
media = resultados.mean()
desvio = resultados.std()

print(media, desvio)